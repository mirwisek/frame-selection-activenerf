{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(hn, hf, dataset, chunk_size=10, img_index=0, nb_bins=192, H=400, W=400):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        hn: near plane distance\n",
    "        hf: far plane distance\n",
    "        dataset: dataset to render\n",
    "        chunk_size (int, optional): chunk size for memory efficiency. Defaults to 10.\n",
    "        img_index (int, optional): image index to render. Defaults to 0.\n",
    "        nb_bins (int, optional): number of bins for density estimation. Defaults to 192.\n",
    "        H (int, optional): image height. Defaults to 400.\n",
    "        W (int, optional): image width. Defaults to 400.\n",
    "        \n",
    "    Returns:\n",
    "        None: None\n",
    "    \"\"\"\n",
    "    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "    data = []   # list of regenerated pixel values\n",
    "    for i in range(int(np.ceil(H / chunk_size))):   # iterate over chunks\n",
    "        # Get chunk of rays\n",
    "        ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(device)\n",
    "        ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(device)        \n",
    "        regenerated_px_values = render_rays(model, ray_origins_, ray_directions_, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "        data.append(regenerated_px_values)\n",
    "    img = torch.cat(data).data.cpu().numpy().reshape(H, W, 3)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(f'novel_views/img_{img_index}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerfModel(nn.Module):\n",
    "    def __init__(self, embedding_dim_pos=10, embedding_dim_direction=4, hidden_dim=128):   \n",
    "        super(NerfModel, self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(nn.Linear(embedding_dim_pos * 6 + 3, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), )\n",
    "        # density estimation\n",
    "        self.block2 = nn.Sequential(nn.Linear(embedding_dim_pos * 6 + hidden_dim + 3, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim + 1), )\n",
    "        # color estimation\n",
    "        self.block3 = nn.Sequential(nn.Linear(embedding_dim_direction * 6 + hidden_dim + 3, hidden_dim // 2), nn.ReLU(), )\n",
    "        self.block4 = nn.Sequential(nn.Linear(hidden_dim // 2, 3), nn.Sigmoid(), )\n",
    "\n",
    "        self.embedding_dim_pos = embedding_dim_pos\n",
    "        self.embedding_dim_direction = embedding_dim_direction\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    @staticmethod\n",
    "    def positional_encoding(x, L):\n",
    "        out = [x]\n",
    "        for j in range(L):\n",
    "            out.append(torch.sin(2 ** j * x))\n",
    "            out.append(torch.cos(2 ** j * x))\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    def forward(self, o, d):\n",
    "        emb_x = self.positional_encoding(o, self.embedding_dim_pos) # emb_x: [batch_size, embedding_dim_pos * 6]\n",
    "        emb_d = self.positional_encoding(d, self.embedding_dim_direction) # emb_d: [batch_size, embedding_dim_direction * 6]\n",
    "        h = self.block1(emb_x) # h: [batch_size, hidden_dim]\n",
    "        tmp = self.block2(torch.cat((h, emb_x), dim=1)) # tmp: [batch_size, hidden_dim + 1]\n",
    "        h, sigma = tmp[:, :-1], self.relu(tmp[:, -1]) # h: [batch_size, hidden_dim], sigma: [batch_size]\n",
    "        h = self.block3(torch.cat((h, emb_d), dim=1)) # h: [batch_size, hidden_dim // 2]\n",
    "        c = self.block4(h) # c: [batch_size, 3]\n",
    "        return c, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accumulated_transmittance(alphas):\n",
    "    accumulated_transmittance = torch.cumprod(alphas, 1)\n",
    "    return torch.cat((torch.ones((accumulated_transmittance.shape[0], 1), device=alphas.device),\n",
    "                      accumulated_transmittance[:, :-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(nerf_model, ray_origins, ray_directions, hn=0, hf=0.5, nb_bins=192):\n",
    "    device = ray_origins.device\n",
    "    \n",
    "    t = torch.linspace(hn, hf, nb_bins, device=device).expand(ray_origins.shape[0], nb_bins)\n",
    "    # Perturb sampling along each ray.\n",
    "    mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "    lower = torch.cat((t[:, :1], mid), -1)\n",
    "    upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "    u = torch.rand(t.shape, device=device)\n",
    "    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n",
    "    delta = torch.cat((t[:, 1:] - t[:, :-1], torch.tensor([1e10], device=device).expand(ray_origins.shape[0], 1)), -1)\n",
    "\n",
    "    # Compute the 3D points along each ray\n",
    "    x = ray_origins.unsqueeze(1) + t.unsqueeze(2) * ray_directions.unsqueeze(1)   # [batch_size, nb_bins, 3]\n",
    "    # Expand the ray_directions tensor to match the shape of x\n",
    "    ray_directions = ray_directions.expand(nb_bins, ray_directions.shape[0], 3).transpose(0, 1) \n",
    "\n",
    "    colors, sigma = nerf_model(x.reshape(-1, 3), ray_directions.reshape(-1, 3))\n",
    "    colors = colors.reshape(x.shape)\n",
    "    sigma = sigma.reshape(x.shape[:-1])\n",
    "\n",
    "    alpha = 1 - torch.exp(-sigma * delta)  # [batch_size, nb_bins]\n",
    "    weights = compute_accumulated_transmittance(1 - alpha).unsqueeze(2) * alpha.unsqueeze(2)\n",
    "    # Compute the pixel values as a weighted sum of colors along each ray\n",
    "    c = (weights * colors).sum(dim=1) # [batch_size, 3]\n",
    "    weight_sum = weights.sum(-1).sum(-1)  # Regularization for white background \n",
    "    return c + 1 - weight_sum.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nerf_model, optimizer, scheduler, data_loader, device='cpu', hn=0, hf=1, nb_epochs=int(1e5),\n",
    "          nb_bins=192, H=400, W=400):\n",
    "    training_loss = []\n",
    "    for _ in tqdm(range(nb_epochs)):\n",
    "        for batch in data_loader:\n",
    "            ray_origins = batch[:, :3].to(device)\n",
    "            ray_directions = batch[:, 3:6].to(device)\n",
    "            ground_truth_px_values = batch[:, 6:].to(device)\n",
    "            \n",
    "            regenerated_px_values = render_rays(nerf_model, ray_origins, ray_directions, hn=hn, hf=hf, nb_bins=nb_bins) \n",
    "            loss = ((ground_truth_px_values - regenerated_px_values) ** 2).sum()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss.append(loss.item())\n",
    "        scheduler.step()\n",
    "\n",
    "        for img_index in range(200):\n",
    "            test(hn, hf, testing_dataset, img_index=img_index, nb_bins=nb_bins, H=H, W=W)\n",
    "    return training_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rizwan/Downloads/BDRP/NeRF.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mMultiStepLR(model_optimizer, milestones\u001b[39m=\u001b[39m[\u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m8\u001b[39m], gamma\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data_loader \u001b[39m=\u001b[39m DataLoader(training_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train(model, model_optimizer, scheduler, data_loader, nb_epochs\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice, hn\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, hf\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, nb_bins\u001b[39m=\u001b[39;49m\u001b[39m192\u001b[39;49m, H\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m, W\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rizwan/Downloads/BDRP/NeRF.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m ((ground_truth_px_values \u001b[39m-\u001b[39m regenerated_px_values) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rizwan/Downloads/BDRP/NeRF.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m training_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/nerf/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/nerf/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "    \n",
    "training_dataset = torch.from_numpy(np.load('nerf_datasets/training_data.pkl', allow_pickle=True))\n",
    "testing_dataset = torch.from_numpy(np.load('nerf_datasets/testing_data.pkl', allow_pickle=True))\n",
    "model = NerfModel(hidden_dim=256).to(device)\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(model_optimizer, milestones=[2, 4, 8], gamma=0.5)\n",
    "data_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True)\n",
    "train(model, model_optimizer, scheduler, data_loader, nb_epochs=16, device=device, hn=2, hf=6, nb_bins=192, H=400, W=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regenerated_px_values torch.Size([1, 3])\n",
      "batch torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(training_dataset, batch_size=1, shuffle=True)\n",
    "for batch in data_loader:\n",
    "    ray_origins = batch[:, :3].to(device)\n",
    "    ray_directions = batch[:, 3:6].to(device)\n",
    "    ground_truth_px_values = batch[:, 6:].to(device)\n",
    "\n",
    "    regenerated_px_values = render_rays(NerfModel(hidden_dim=256).to('cpu'), ray_origins, ray_directions, hn=2, hf=6, nb_bins=192) \n",
    "    print(\"regenerated_px_values\",regenerated_px_values.shape)\n",
    "    print(\"batch\",batch.shape)\n",
    "    break\n",
    "    loss = ((ground_truth_px_values - regenerated_px_values) ** 2).sum()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    training_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
